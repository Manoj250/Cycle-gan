{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install git+https://www.github.com/keras-team/keras-contrib.git -q","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir outputs","metadata":{"id":"bHYWufOOGPWZ","execution":{"iopub.status.busy":"2023-02-08T06:03:46.136283Z","iopub.execute_input":"2023-02-08T06:03:46.136697Z","iopub.status.idle":"2023-02-08T06:03:47.252934Z","shell.execute_reply.started":"2023-02-08T06:03:46.136655Z","shell.execute_reply":"2023-02-08T06:03:47.251474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,Input,Conv2DTranspose,Concatenate,Activation\nfrom keras.layers import LeakyReLU\nfrom keras.initializers import RandomNormal\nfrom keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\nfrom keras.utils.vis_utils import plot_model","metadata":{"id":"alCu14mRNxHq","execution":{"iopub.status.busy":"2023-02-08T06:03:47.255285Z","iopub.execute_input":"2023-02-08T06:03:47.255678Z","iopub.status.idle":"2023-02-08T06:03:47.262758Z","shell.execute_reply.started":"2023-02-08T06:03:47.255644Z","shell.execute_reply":"2023-02-08T06:03:47.261430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport random","metadata":{"id":"-SNSzvb_N1Tp","execution":{"iopub.status.busy":"2023-02-08T06:03:47.264508Z","iopub.execute_input":"2023-02-08T06:03:47.264910Z","iopub.status.idle":"2023-02-08T06:03:47.277665Z","shell.execute_reply.started":"2023-02-08T06:03:47.264872Z","shell.execute_reply":"2023-02-08T06:03:47.276423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnet_block(number_of_filters,prev_layer):\n    weight_initialization = RandomNormal(stddev=0.02)\n    \n    block_part1 = Conv2D(number_of_filters, (3,3), padding='same', kernel_initializer=weight_initialization)(prev_layer)\n    block_part1 = InstanceNormalization(axis=-1)(block_part1)\n    block_part1 = Activation('relu')(block_part1)\n\n    block_part2 = Conv2D(number_of_filters, (3,3), padding='same', kernel_initializer=weight_initialization)(block_part1)\n    block_part2 = InstanceNormalization(axis=-1)(block_part2)\n\n    block = Concatenate()([block_part2, prev_layer])\n    return block","metadata":{"id":"Fh5usOOcN1ai","execution":{"iopub.status.busy":"2023-02-08T06:03:47.282507Z","iopub.execute_input":"2023-02-08T06:03:47.282940Z","iopub.status.idle":"2023-02-08T06:03:47.292476Z","shell.execute_reply.started":"2023-02-08T06:03:47.282884Z","shell.execute_reply":"2023-02-08T06:03:47.290990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#patch gan discriminator \n#C64-C128-C256-C512\n\ndef discriminator(image_shape,model_name):\n    weight_initialization = RandomNormal(stddev=0.02)\n    in_image = Input(shape=image_shape)\n    #the below resolutions are for 256,256\n    # C64\n    #128x128\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # C128\n    #64x64\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # C256\n    #32x32\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # C512\n    #16x16\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # second last output layer\n    #16x16 no strides\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=weight_initialization)(d)\n    d = InstanceNormalization(axis=-1)(d)\n    d = LeakyReLU(alpha=0.2)(d)\n\n    # patch output\n    #16x16\n    patch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=weight_initialization)(d)\n\n    model = Model(in_image, patch_out,name = model_name)\n    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss_weights=[0.5])\n    return model","metadata":{"id":"UOg25F5XN1hf","execution":{"iopub.status.busy":"2023-02-08T06:03:47.295938Z","iopub.execute_input":"2023-02-08T06:03:47.296241Z","iopub.status.idle":"2023-02-08T06:03:47.310262Z","shell.execute_reply.started":"2023-02-08T06:03:47.296213Z","shell.execute_reply":"2023-02-08T06:03:47.308961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#c7s1-64,d128,d256,R256,R256,R256,R256,R256,R256,u128,u64,c7s1-3\n\ndef generator(image_shape,resnet_block_count,name):\n    weight_initialization = RandomNormal(stddev=0.02)\n    in_image = Input(shape=image_shape)\n    #the below resolutions are for 256,256\n    \n    #encoder\n    \n    # c7s1-64 7x7 kernel stride=1 64 filters\n    #256x256\n    g = Conv2D(64, (7,7), padding='same', kernel_initializer=weight_initialization)(in_image)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n\n    # d128\n    #128x128\n    g = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n\n    # d256\n    #64x64\n    g = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n\n    # R256\n    #9 resnet blocks where dimension does not decrease\n    for _ in range(resnet_block_count):\n        g = resnet_block(256, g)\n\n    # u128\n    #128x128\n    g = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n\n    # u64\n    #256x256\n    g = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=weight_initialization)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    g = Activation('relu')(g)\n\n    # c7s1-3 \n    #as our image is gray scale we will use c7s1-1\n    #256x256\n    g = Conv2D(1, (7,7), padding='same', kernel_initializer=weight_initialization)(g)\n    g = InstanceNormalization(axis=-1)(g)\n    out_image = Activation('tanh')(g)\n\n    model = Model(in_image, out_image) #model is not directly compiled because the weights of generator are updated using composite models\n    return model","metadata":{"id":"i4sSPampN1oP","execution":{"iopub.status.busy":"2023-02-08T06:03:47.313773Z","iopub.execute_input":"2023-02-08T06:03:47.315345Z","iopub.status.idle":"2023-02-08T06:03:47.328949Z","shell.execute_reply.started":"2023-02-08T06:03:47.315243Z","shell.execute_reply":"2023-02-08T06:03:47.327912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#4 losses for composite model\n#adveserial loss (normal gan loss) using mse\n#forward cycle (mae)\n#backward cycle (mae)\n#identity loss (mae)","metadata":{"id":"RDycfFiZN1vD","execution":{"iopub.status.busy":"2023-02-08T06:03:47.331928Z","iopub.execute_input":"2023-02-08T06:03:47.332713Z","iopub.status.idle":"2023-02-08T06:03:47.342539Z","shell.execute_reply.started":"2023-02-08T06:03:47.332673Z","shell.execute_reply":"2023-02-08T06:03:47.341465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def composite_model(image_shape,g_model_1, d_model, g_model_2,name):\n    g_model_1.trainable = True\n    d_model.trainable = False\n    g_model_2.trainable = False\n\n    # discriminator element\n    #domain-B_image --> generator A --> domain-A_image --> discriminator(is the image in domain A or not) \n    input_gen = Input(shape=image_shape)\n    gen1_out = g_model_1(input_gen)\n    output_d = d_model(gen1_out)\n\n    # identity element\n    #domain-A_image --> generator A --> domain-A_image\n\n    input_id = Input(shape=image_shape)\n    output_id = g_model_1(input_id)\n\n    # forward cycle\n    #domain-B_image --> generator A --> domain-A_image --> generator B --> domain-B_image\n    output_f = g_model_2(gen1_out)\n\n    # backward cycle\n    #domain-A_image --> generator B --> domain-B_image --> generator A --> domain-A_image\n    gen2_out = g_model_2(input_id)\n    output_b = g_model_1(gen2_out)\n\n    #input_id layer = domain A image\n    #input_gen = domain B image\n\n    model = Model([input_gen, input_id], [output_d, output_id, output_f, output_b],name = name)\n    opt = Adam(learning_rate=0.0002, beta_1=0.5)\n    model.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n\n    return model","metadata":{"id":"qwCovgWPN11c","execution":{"iopub.status.busy":"2023-02-08T06:03:47.344330Z","iopub.execute_input":"2023-02-08T06:03:47.344888Z","iopub.status.idle":"2023-02-08T06:03:47.355651Z","shell.execute_reply.started":"2023-02-08T06:03:47.344764Z","shell.execute_reply":"2023-02-08T06:03:47.354525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = (256,256,1)\n\n\ngen_a_to_b = generator(img_shape,9,\"gen_a_to_b\")\ngen_b_to_a = generator(img_shape,9,\"gen_b_to_a\")\n\ndisc_a = discriminator(img_shape,\"disc_a\")\ndisc_b = discriminator(img_shape,\"disc_b\")\n\n#two composite models required for training two generators\ncomposite_a_to_b = composite_model(img_shape,gen_a_to_b,disc_b,gen_b_to_a,\"composite_a_to_b\")\n\ncomposite_b_to_a = composite_model(img_shape,gen_b_to_a,disc_a,gen_a_to_b,\"composite_b_to_a\")","metadata":{"id":"pGs84GvrWf_R","execution":{"iopub.status.busy":"2023-02-08T06:03:47.357673Z","iopub.execute_input":"2023-02-08T06:03:47.358121Z","iopub.status.idle":"2023-02-08T06:03:52.732813Z","shell.execute_reply.started":"2023-02-08T06:03:47.358083Z","shell.execute_reply":"2023-02-08T06:03:52.731706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(gen_a_to_b)","metadata":{"id":"IYZEIf1abzqx","outputId":"63efe60d-4992-4602-d913-e7f61c316498","execution":{"iopub.status.busy":"2023-02-08T06:03:52.734466Z","iopub.execute_input":"2023-02-08T06:03:52.734856Z","iopub.status.idle":"2023-02-08T06:03:53.368233Z","shell.execute_reply.started":"2023-02-08T06:03:52.734814Z","shell.execute_reply":"2023-02-08T06:03:53.367100Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training steps\n\n# 1.train gen_a_to_b\n# 2.train disc_b\n# 3.train gen_b_to_a\n# 4.train disc_a","metadata":{"id":"th_lOx6KZcDv","execution":{"iopub.status.busy":"2023-02-08T06:03:53.370209Z","iopub.execute_input":"2023-02-08T06:03:53.371416Z","iopub.status.idle":"2023-02-08T06:03:53.376634Z","shell.execute_reply.started":"2023-02-08T06:03:53.371374Z","shell.execute_reply":"2023-02-08T06:03:53.375388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_dataset(path):\n    images = []\n    files = os.listdir(path)    \n    for f in files:\n        img = Image.open(os.path.join(path,f))\n        img = img.resize((256,256),Image.BICUBIC).convert(\"L\")\n        img = np.asarray(img)\n        img = (img / 127.5) - 1.\n        images.append(img)\n    images =  np.array(images)\n    images = np.expand_dims(images,axis=-1)\n    return images","metadata":{"id":"kLaRumY_v51U","execution":{"iopub.status.busy":"2023-02-08T06:03:53.378258Z","iopub.execute_input":"2023-02-08T06:03:53.379343Z","iopub.status.idle":"2023-02-08T06:03:53.389108Z","shell.execute_reply.started":"2023-02-08T06:03:53.379307Z","shell.execute_reply":"2023-02-08T06:03:53.387947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def save_picture(model_name,epoch,step):\n    test_imgs = []\n    images = None\n\n    if model_name == \"gen_a_to_b\":\n        for _ in range(9):\n            test_imgs.append(test_a[random.randint(0,test_a.shape[0]-1)])\n        images = gen_a_to_b.predict(np.array(test_imgs))\n    else:\n        for _ in range(9):\n            test_imgs.append(test_b[random.randint(0,test_b.shape[0]-1)])\n        images = gen_b_to_a.predict(np.array(test_imgs))\n\n    fig, axs = plt.subplots(3,3)\n    count = 0\n    for i in range(3):\n        for j in range(3):\n            axs[i,j].imshow(np.squeeze(images[count]*0.5+0.5),cmap=\"gray\")\n            axs[i,j].axis('off')\n            count += 1\n    plt.show()\n    plt.close()\n    fig.savefig(f\"outputs/{model_name}-{epoch}-{step}.png\")","metadata":{"id":"m7fYl4dWSQ4l","execution":{"iopub.status.busy":"2023-02-08T06:03:53.395007Z","iopub.execute_input":"2023-02-08T06:03:53.395412Z","iopub.status.idle":"2023-02-08T06:03:53.405938Z","shell.execute_reply.started":"2023-02-08T06:03:53.395383Z","shell.execute_reply":"2023-02-08T06:03:53.404623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_a = make_dataset(\"/kaggle/input/horse2zebra-dataset/trainA\")\ntrain_b = make_dataset(\"/kaggle/input/horse2zebra-dataset/trainB\")\ntest_a = make_dataset(\"/kaggle/input/horse2zebra-dataset/testA\")\ntest_b = make_dataset(\"/kaggle/input/horse2zebra-dataset/testB\")","metadata":{"id":"d-Y10y7Cv54p","execution":{"iopub.status.busy":"2023-02-08T06:03:53.407704Z","iopub.execute_input":"2023-02-08T06:03:53.408231Z","iopub.status.idle":"2023-02-08T06:04:02.645762Z","shell.execute_reply.started":"2023-02-08T06:03:53.408079Z","shell.execute_reply":"2023-02-08T06:04:02.644663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_a.shape,train_b.shape,test_a.shape,test_b.shape)\nprint(np.max(train_a),np.min(train_a))","metadata":{"id":"OyAHdIALJtgY","outputId":"9d9fc402-acc9-4001-c94e-f9d2838bc8a9","execution":{"iopub.status.busy":"2023-02-08T06:04:02.647297Z","iopub.execute_input":"2023-02-08T06:04:02.647697Z","iopub.status.idle":"2023-02-08T06:04:02.746406Z","shell.execute_reply.started":"2023-02-08T06:04:02.647655Z","shell.execute_reply":"2023-02-08T06:04:02.745319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_real_samples(domain, n_samples, patch_shape):\n    x = None\n    if domain == \"train_a\":\n        ix = np.random.randint(0, train_a.shape[0]-1, n_samples)\n        x = train_a[ix]\n    else:\n        ix = np.random.randint(0, train_b.shape[0]-1, n_samples)\n        x = train_b[ix]\n    \n    y = np.ones((n_samples, patch_shape, patch_shape, 1))\n    return x, y\n","metadata":{"id":"Fg8YG07PMfXE","execution":{"iopub.status.busy":"2023-02-08T06:04:02.748117Z","iopub.execute_input":"2023-02-08T06:04:02.748500Z","iopub.status.idle":"2023-02-08T06:04:02.755355Z","shell.execute_reply.started":"2023-02-08T06:04:02.748448Z","shell.execute_reply":"2023-02-08T06:04:02.754182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_fake_samples(model_name,data,patch_shape):\n    x = None\n    if model_name == \"gen_a_to_b\":\n        x = gen_a_to_b.predict(data)\n    else:\n        x = gen_b_to_a.predict(data)\n    \n    y = np.zeros((len(x), patch_shape, patch_shape, 1))\n    return x, y","metadata":{"id":"ynvkcqqGR5SF","execution":{"iopub.status.busy":"2023-02-08T06:04:02.757093Z","iopub.execute_input":"2023-02-08T06:04:02.757441Z","iopub.status.idle":"2023-02-08T06:04:02.766233Z","shell.execute_reply.started":"2023-02-08T06:04:02.757408Z","shell.execute_reply":"2023-02-08T06:04:02.765091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#update the discriminators using a history of generated images & Maximum pool size is 50\n# update image pool for fake images\n\ndef update_image_pool(pool, images, max_size=50):\n\tselected = list()\n\tfor image in images:\n\t\tif len(pool) < max_size:\n\t\t\t# stock the pool\n\t\t\tpool.append(image)\n\t\t\tselected.append(image)\n\t\telif random.random() < 0.5:\n\t\t\t# use image, but don't add it to the pool\n\t\t\tselected.append(image)\n\t\telse:\n\t\t\t# replace an existing image and use replaced image\n\t\t\tix = random.randint(0, len(pool)-1)\n\t\t\tselected.append(pool[ix])\n\t\t\tpool[ix] = image\n\treturn np.asarray(selected)","metadata":{"id":"cGTOw18SR8ZH","execution":{"iopub.status.busy":"2023-02-08T06:04:02.767853Z","iopub.execute_input":"2023-02-08T06:04:02.768232Z","iopub.status.idle":"2023-02-08T06:04:02.780577Z","shell.execute_reply.started":"2023-02-08T06:04:02.768199Z","shell.execute_reply":"2023-02-08T06:04:02.779544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\nbatch_size = 1\nsteps_per_epoch = train_a.shape[0]\npatch_size = 16\npoolA, poolB = list(), list()\n\nfor i in range(epochs):\n    print(\"#################\",i+1,\"#################\")\n    for j in range(steps_per_epoch):\n        print(\"step \",j+1,end=\"\\r\")\n        \n        #real samples\n        X_realA, y_realA = generate_real_samples(\"train_a\", batch_size, patch_size)\n        X_realB, y_realB = generate_real_samples(\"train_b\", batch_size, patch_size)\n\t\t\n        # fake samples\n        X_fakeA, y_fakeA = generate_fake_samples(\"gen_b_to_a\", X_realB, patch_size)\n        X_fakeB, y_fakeB = generate_fake_samples(\"gen_a_to_b\", X_realA, patch_size)\n  \n\t\t# update Pool\n        X_fakeA = update_image_pool(poolA, X_fakeA)\n        X_fakeB = update_image_pool(poolB, X_fakeB)\n  \n\t\t# update generator B->A via adversarial and cycle loss\n        g_loss2, _, _, _, _  = composite_b_to_a.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n  \n\t\t# update discriminator for A -> [real/fake]\n        dA_loss1 = disc_a.train_on_batch(X_realA, y_realA)\n        dA_loss2 = disc_a.train_on_batch(X_fakeA, y_fakeA)\n  \n\t\t# update generator A->B via adversarial and cycle loss\n        g_loss1, _, _, _, _ = composite_a_to_b.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n  \n\t\t# update discriminator for B -> [real/fake]\n        dB_loss1 = disc_b.train_on_batch(X_realB, y_realB)\n        dB_loss2 = disc_b.train_on_batch(X_fakeB, y_fakeB)\n  \n#         print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))\n        if j%100 == 0:\n            save_picture(\"gen_a_to_b\",i+1,j+1)\n            save_picture(\"gen_b_to_a\",i+1,j+1)","metadata":{"id":"TwfJ-XB-KhpP","outputId":"04684f96-36b6-4393-e575-b0c5eaf7a0c0","execution":{"iopub.status.busy":"2023-02-08T06:04:02.782060Z","iopub.execute_input":"2023-02-08T06:04:02.782574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_a_to_b.save(\"gen_a_to_b.h5\")\ngen_b_to_a.save(\"gen_b_to_a.h5\")","metadata":{"id":"jW4YsVsIRzYq","outputId":"2cd4817d-a3c5-469c-9a65-0c40c00acba1","trusted":true},"execution_count":null,"outputs":[]}]}